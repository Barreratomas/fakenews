PROYECTO IA â€“ DETECCIÃ“N DE FAKE NEWS (VERSIÃ“N CON LINKS)
ğŸŸ¦ PASO 0 â€“ DEFINÃ EL ALCANCE (ACTUALIZADO)

Antes de codear, dejÃ¡ esto por escrito en el README:

âœ” Idioma inicial: espaÃ±ol
âœ” Entrada:

âœ… Texto de noticia

âœ… URL de noticia

âœ” Salida:

Fake / Real

Probabilidad

ExplicaciÃ³n bÃ¡sica

(opcional) Texto extraÃ­do desde el link

ğŸ“Œ AclaraciÃ³n clave en README:

â€œCuando se ingresa una URL, el sistema extrae automÃ¡ticamente el contenido del artÃ­culo antes de analizarlo.â€

ğŸ‘‰ Esto ya lo pone un nivel arriba.

ğŸŸ¦ PASO 1 â€“ SETUP DEL ENTORNO (ACTUALIZADO)
âœ” Stack base

Sumamos scraping:

Python 3.10+
PyTorch
transformers
datasets
pandas
scikit-learn
fastapi
uvicorn
gradio
faiss-cpu
newspaper3k
beautifulsoup4
lxml


ğŸ‘‰ newspaper3k es clave para URLs.

ğŸŸ¦ PASO 2 â€“ DATASETS (SIN CAMBIOS, PERO ACLARADO)

Vas a entrenar solo con texto, no con links.

Dataset que vas a usar (perfecto para este proyecto):

âœ” train.csv
âœ” test.csv
âœ” onlytrue1000.csv
âœ” onlyfakes1000.csv

ğŸ“Œ En README:

â€œEl modelo se entrena con texto plano; los links se procesan en inferencia.â€

Esto es correcto y profesional.

ğŸŸ¦ PASO 3 â€“ PREPROCESAMIENTO NLP (IGUAL)

âœ” Limpieza mÃ­nima
âœ” Split train / val / test
âœ” TokenizaciÃ³n con Hugging Face

ğŸš« Nada de TF-IDF
âœ… Full Transformers

ğŸŸ¦ PASO 4 â€“ MODELO BASE (IGUAL)

âœ” roberta-base o distilbert-base-uncased
âœ” ClasificaciÃ³n binaria
âœ” Guardar mÃ©tricas baseline

ğŸ‘‰ Todo esto queda idÃ©ntico.

ğŸŸ¦ PASO 5 â€“ MEJORAS PROFESIONALES (IGUAL)

âœ” Class weights
âœ” Scheduler
âœ” Early stopping

ğŸŸ¦ PASO 6 â€“ EXPLICABILIDAD (IGUAL)

âœ” SHAP / LIME
âœ” AtenciÃ³n
âœ” Frases clave

ğŸ“Œ Importante:
La explicaciÃ³n se hace sobre el texto extraÃ­do, no sobre el HTML.

ğŸŸ¦ PASO 7 â€“ MODELO AVANZADO (IGUAL)

âœ” DeBERTa v3
âœ” LoRA (PEFT)

ğŸ†• ğŸŸ¦ PASO 8 â€“ EXTRACCIÃ“N DE NOTICIAS DESDE LINKS (NUEVO)

ğŸ”¥ Este es el paso que te diferencia.

âœ” QuÃ© aprender

Web scraping bÃ¡sico

Parsing de artÃ­culos periodÃ­sticos

Manejo de errores

âœ” QuÃ© implementar
from newspaper import Article

def extract_article_from_url(url):
    article = Article(url, language="en")
    article.download()
    article.parse()

    if len(article.text) < 500:
        raise ValueError("ArtÃ­culo demasiado corto")

    return {
        "title": article.title,
        "text": article.text
    }

âœ” Casos a manejar

Link invÃ¡lido

ArtÃ­culo corto

Paywall

Error de descarga

ğŸ“Œ Esto no es NLP, pero es ingenierÃ­a real.

ğŸŸ¦ PASO 9 â€“ PIPELINE UNIFICADO (NUEVO)

UnificÃ¡s todo asÃ­:

INPUT
 â”œâ”€ Texto â†’ Modelo
 â””â”€ URL â†’ Extractor â†’ Texto â†’ Modelo


En cÃ³digo:

def predict(input_data):
    if input_data.type == "url":
        text = extract_article_from_url(input_data.value)["text"]
    else:
        text = input_data.value

    return model_predict(text)


ğŸ‘‰ Arquitectura limpia, modular.

ğŸŸ¦ PASO 10 â€“ SISTEMA LLM + RAG (VANGUARDIA)

Ahora con URLs esto brilla mÃ¡s.

âœ” ConvertÃ­s noticias reales a embeddings
âœ” FAISS / Chroma
âœ” RecuperÃ¡s noticias similares
âœ” LLM compara narrativas

Ejemplo:

â€œEsta noticia afirma X, pero 5 fuentes confiables dicen Y.â€

ğŸ”¥ Esto ya es fact-checking asistido.

ğŸŸ¦ PASO 11 â€“ API BACKEND (ACTUALIZADO)
Endpoint Ãºnico
POST /predict

Input
{
  "type": "url",
  "content": "https://news.site/article"
}


o

{
  "type": "text",
  "content": "full article text..."
}

Output
{
  "label": "FAKE",
  "confidence": 0.92,
  "explanation": "...",
  "extracted_title": "..."
}


ğŸ‘‰ Esto es API de producto.

ğŸŸ¦ PASO 12 â€“ INTERFAZ (ACTUALIZADA)

âœ” Selector:

Texto

URL

âœ” Preview:

Texto extraÃ­do

Resultado

âœ” BotÃ³n:

â€œAnalizar noticiaâ€

ğŸŸ¦ PASO 13 â€“ DOCKER + DEPLOY (IGUAL)

âœ” Dockerfile
âœ” README
âœ” Deploy

ğŸŸ¦ PASO 14 â€“ DOCUMENTACIÃ“N (ACTUALIZADA)

AgregÃ¡ secciÃ³n:

Limitaciones del sistema

No funciona bien con paywalls

No garantiza veracidad absoluta

Depende de estructura del sitio

ğŸ“Œ Esto suma puntos, no resta.

ğŸ RESULTADO FINAL (VERSIÃ“N CON LINKS)

âœ” Fake news detection realista
âœ” Entrada por texto o URL
âœ” NLP moderno
âœ” Transformers
âœ” Explainability
âœ” Scraping responsable
âœ” API
âœ” Deploy
âœ” Portfolio top-tier

Un recruiter va a pensar:

â€œEste proyecto podrÃ­a ponerse en producciÃ³n con poco esfuerzo.â€